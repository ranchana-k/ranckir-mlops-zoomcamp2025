{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02ba3708-ba0f-4c13-90d5-4c350b3e061e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mlflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflow\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpickle\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extraction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DictVectorizer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'mlflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import pickle\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "from hyperopt.pyll import scope\n",
    "import numpy as np\n",
    "import os\n",
    "from mlflow.models.signature import infer_signature\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d03d6a-a9a8-4669-89ec-0608b71117f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_experiment():\n",
    "    mlflow.set_tracking_uri(\"sqlite:///mlflow_test.db\")\n",
    "    mlflow.set_experiment(\"nyc_taxi_hw3_test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71d965a1-aab2-451d-acb6-963daa0b2897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.apply(lambda td: td.total_seconds()/60)\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "    categorical = ['PULocationID','DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    print(f\"{filename} has {len(df)} records.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70357dc2-85d2-48ad-9e89-56bcccb51220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df: pd.DataFrame, dv: DictVectorizer, fit_dv: bool = False):\n",
    "    \n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    numerical = ['trip_distance']\n",
    "    dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    if fit_dv:\n",
    "        X = dv.fit_transform(dicts)\n",
    "    else:\n",
    "        X = dv.transform(dicts)\n",
    "    return X, dv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a9867821-7ba2-4445-98b2-db10494220b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dump_pickle(obj, filename: str):\n",
    "    with open(filename, \"wb\") as f_out:\n",
    "        return pickle.dump(obj, f_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6955de3a-7d0a-4772-b3a9-8486220279e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_data_prep(raw_data_path: str, dest_path: str, dataset: str = \"green\"):\n",
    "    # print(raw_data_path)\n",
    "    # Load parquet files\n",
    "    df_train = read_dataframe(\n",
    "        os.path.join(raw_data_path, f\"{dataset}_tripdata_2023-03.parquet\")\n",
    "    )\n",
    "    df_val = read_dataframe(\n",
    "        os.path.join(raw_data_path, f\"{dataset}_tripdata_2023-04.parquet\")\n",
    "    )\n",
    "    # df_test = read_dataframe(\n",
    "    #     os.path.join(raw_data_path, f\"{dataset}_tripdata_2023-03.parquet\")\n",
    "    # )\n",
    "\n",
    "    # Extract the target\n",
    "    target = 'duration'\n",
    "    y_train = df_train[target].values\n",
    "    y_val = df_val[target].values\n",
    "    # y_test = df_test[target].values\n",
    "\n",
    "    # Fit the DictVectorizer and preprocess data\n",
    "    dv = DictVectorizer()\n",
    "    X_train, dv = preprocess(df_train, dv, fit_dv=True)\n",
    "    X_val, _ = preprocess(df_val, dv, fit_dv=False)\n",
    "    # X_test, _ = preprocess(df_test, dv, fit_dv=False)\n",
    "\n",
    "    # Create dest_path folder unless it already exists\n",
    "    # os.makedirs(dest_path, exist_ok=True)\n",
    "\n",
    "    \n",
    "    # Save DictVectorizer and datasets\n",
    "    dump_pickle(dv, os.path.join(dest_path, \"dv.pkl\"))\n",
    "    dump_pickle((X_train, y_train), os.path.join(dest_path, \"train.pkl\"))\n",
    "    dump_pickle((X_val, y_val), os.path.join(dest_path, \"val.pkl\"))\n",
    "    # dump_pickle((X_test, y_test), os.path.join(dest_path, \"test.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4053276b-c3ac-493c-920c-4eb4f680f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(filename: str):\n",
    "    print(filename)\n",
    "\n",
    "    with open(filename, \"rb\") as f_in:\n",
    "        return pickle.load(f_in)\n",
    "def train_model(data_path):\n",
    "    \n",
    "    with mlflow.start_run() as run:\n",
    "        X_train, y_train = load_pickle(os.path.join(data_path, \"train.pkl\"))\n",
    "        X_val, y_val = load_pickle(os.path.join(data_path, \"val.pkl\"))\n",
    "        \n",
    "        lr = LinearRegression()\n",
    "        \n",
    "        lr.fit(X_train, y_train)\n",
    "\n",
    "      \n",
    "        mlflow.log_param(\"intercept_\", lr.intercept_)\n",
    "        y_pred = lr.predict(X_val)\n",
    "        # ตัวอย่างข้อมูลที่ใช้ infer\n",
    "        input_example = X_train[:5]\n",
    "        signature = infer_signature(X_train[:5], lr.predict(X_train[:5]))\n",
    "\n",
    "        rmse = root_mean_squared_error(y_val, y_pred)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.sklearn.log_model(sk_model=lr, artifact_path=\"model\",\n",
    "                                 input_example=input_example,\n",
    "                                 signature=signature)\n",
    "        run_id = run.info.run_id\n",
    "        \n",
    "        \n",
    "    return run_id\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73f8cdb5-9da3-42a2-9e3f-bf360116d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_model_to_mlflow(run_id: str, model_name: str, artifact_path: str = \"model\") -> str:\n",
    "    \"\"\"\n",
    "    Register a model from a completed MLflow run to the MLflow Model Registry.\n",
    "\n",
    "    Parameters:\n",
    "        run_id (str): The run ID of the MLflow run.\n",
    "        model_name (str): The name to register the model under in the MLflow Model Registry.\n",
    "        artifact_path (str): The artifact path used when logging the model. Default is \"model\".\n",
    "\n",
    "    Returns:\n",
    "        str: The model URI that was registered.\n",
    "    \"\"\"\n",
    "    model_uri = f\"runs:/{run_id}/{artifact_path}\"\n",
    "\n",
    "    mlflow.register_model(\n",
    "        model_uri=model_uri,\n",
    "        name=model_name\n",
    "    )\n",
    "\n",
    "    print(f\"✅ Model registered: {model_name} from run_id={run_id}\")\n",
    "    return model_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d30955c4-2267-4f1c-9d91-14b8ebb9f437",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0f98563-3caa-42c9-80e9-83501aa14fee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./airflow_db/data/yellow_tripdata_2023-03.parquet has 3316216 records.\n"
     ]
    }
   ],
   "source": [
    "df = read_dataframe(\"./airflow_db/data/yellow_tripdata_2023-03.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5ef9c7d3-9260-406f-a850-bdb687920d81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3316216 entries, 0 to 3403765\n",
      "Data columns (total 20 columns):\n",
      " #   Column                 Dtype         \n",
      "---  ------                 -----         \n",
      " 0   VendorID               int32         \n",
      " 1   tpep_pickup_datetime   datetime64[us]\n",
      " 2   tpep_dropoff_datetime  datetime64[us]\n",
      " 3   passenger_count        float64       \n",
      " 4   trip_distance          float64       \n",
      " 5   RatecodeID             float64       \n",
      " 6   store_and_fwd_flag     object        \n",
      " 7   PULocationID           object        \n",
      " 8   DOLocationID           object        \n",
      " 9   payment_type           int64         \n",
      " 10  fare_amount            float64       \n",
      " 11  extra                  float64       \n",
      " 12  mta_tax                float64       \n",
      " 13  tip_amount             float64       \n",
      " 14  tolls_amount           float64       \n",
      " 15  improvement_surcharge  float64       \n",
      " 16  total_amount           float64       \n",
      " 17  congestion_surcharge   float64       \n",
      " 18  Airport_fee            float64       \n",
      " 19  duration               float64       \n",
      "dtypes: datetime64[us](2), float64(13), int32(1), int64(1), object(3)\n",
      "memory usage: 518.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea2f6bb8-7f55-4753-8971-6953eb77bffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./airflow_db/data/yellow_tripdata_2023-03.parquet has 3316216 records.\n",
      "./airflow_db/data/yellow_tripdata_2023-04.parquet has 3199715 records.\n"
     ]
    }
   ],
   "source": [
    "run_data_prep(\"./airflow_db/data\",\"./airflow_db/data_pickled\",\"yellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b76ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow ui --port 5001 --backend-store-uri sqlite:///mlflow_test.db --default-artifact-root ./mlruns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "072b402b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:18:34 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: Unable to allocate 12.8 GiB for an array with shape (3316216, 519) and data type float64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./airflow_db/data_pickled/train.pkl\n",
      "./airflow_db/data_pickled/val.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/09 09:18:39 WARNING mlflow.sklearn: Failed to log evaluation dataset information to MLflow Tracking. Reason: Unable to allocate 12.4 GiB for an array with shape (3199715, 519) and data type float64\n"
     ]
    }
   ],
   "source": [
    "run_id = train_model('./airflow_db/data_pickled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f71727ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model registered: linearregression from run_id=9262b79673d1459d84d2c1fde7690c8a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'linearregression' already exists. Creating a new version of this model...\n",
      "Created version '4' of model 'linearregression'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'runs:/9262b79673d1459d84d2c1fde7690c8a/model'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "register_model_to_mlflow(run_id, 'linearregression')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
